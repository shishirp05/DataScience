# -*- coding: utf-8 -*-
"""Shishir_Paltanwale_CAM_C101_W5_Mini-project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16Kqy96nVHrIK8i0nXpTUqEXQHYDzm7CX

**First things first** - please go to 'File' and select 'Save a copy in Drive' so that you have your own version of this activity set up and ready to use.
Remember to update your Course 1 notebook with links to your own work once completed!

# Mini-project 5.3 Detecting the anomalous activity of a ship’s engine

**Welcome to your first mini-project: Detecting the anomalous activity of a ship’s engine!**

This mini-project allows you to dive deep into a real-world challenge, applying and honing the data science skills you've been cultivating so far. In this immersive exploration into detecting the anomalous activity of a ship’s engine, you can practically apply the concepts you've learned over the past few weeks.

A poorly maintained ship engine in the supply chain industry can lead to inefficiencies, increased fuel consumption, higher risks of malfunctions, and potential safety hazards. Your challenge in this project is to apply critical thinking and ML concepts to design and implement a robust anomaly detection model.

Please set aside approximately **12 hours** to complete the mini-project.

<br></br>

## **Business context**
You are provided with a real data set to identify anomalous activity in a ship’s engine functionality (Devabrat,  2022). As you work through this project, keep in mind that, typically speaking, anomalies would make up a minority of the data points (i.e., about 1% to 5% of the data points would be anomalies).

The data set contains six important features continuously monitored to evaluate the engine's status as ‘good’ or ‘bad’. These features are:
- **Engine rpm (revolutions per minute):** A high rpm indicates the engine is operating at a higher speed than designed for prolonged periods, which can lead to overheating, excessive wear, and eventual failure. A low rpm could signal a lack of power, issues with fuel delivery, or internal mechanical problems.
- **Lubrication oil pressure:** Low lubrication oil pressure indicates insufficient lubrication, leading to increased friction, overheating, and engine damage. A high lubrication oil pressure could signal a blockage in the oil delivery system, potentially causing seal or gasket failure.
- **Fuel pressure:** High fuel pressure can cause poor engine performance and incomplete combustion, indicating fuel pump or filter issues. A low fuel pressure may result in excessive fuel consumption, poor emissions, or damage to the fuel injectors.
- **Coolant pressure:** Low coolant pressure indicates a potential leak in the cooling system or a coolant pump failure, risking engine overheating. A high coolant pressure could be a sign of a blockage in the cooling system or a failing head gasket, which can also lead to overheating.
- **Lubrication oil temperature:** High lubrication oil temperature suggests the oil is overheating, which can degrade its lubricating properties and lead to engine damage. A low lubrication oil temperature may indicate it is not reaching its optimal operating temperature, potentially causing inadequate lubrication.
- **Coolant temperature:** High coolant temperature signals overheating, which various issues, including a failed thermostat, coolant leak, or insufficient coolant flow can cause. A low coolant temperature could suggest the engine is not reaching its optimal operating temperature, affecting performance and efficiency.

Issues with engines could lead to engine malfunctions, potential safety hazards, and downtime (e.g. delayed deliveries), resulting in the breakdown of a ship’s overall functionality, consequently impacting the business, such as affecting revenue via failure to deliver goods. By predicting timely maintenance, the business aims to increase profit by reducing downtime, reducing safety risks for the crew, limiting fuel consumption, and increasing customer satisfaction through timely deliveries.

Your task is to develop a robust anomaly detection system to protect a company’s shipping fleet by evaluating engine functionality. Therefore, you’ll explore the data and:
- employ preprocessing and feature engineering
- perform anomaly detection.

You must prepare a report illustrating your insights to the prospective stakeholders, showing how your solution will save the business money and build trust with its stakeholders. At this stage of the project, the main question you need to consider is:
- What insights can be gained from the data, and what recommendations can be made to the company based on these insights? For example, which features need to be monitored closely, and what are the thresholds for anomalous observations? Which statistical or ML technique is the best for anomaly detection based on **this data set**, and which feature (univariate approach) or combination of features (multivariate approach) can predict maintenance?

<br></br>

> **Disclaimer**
>
> Please note that although a real-life data set was provided, the business context in this project is fictitious. Any resemblance to companies and persons (living or dead) is coincidental. The course designers and hosts assume no responsibility or liability for any errors or omissions in the content of the business context and data sets. The information in the data sets is provided on an 'as is' basis with no guarantees of completeness, accuracy, usefulness, or timeliness.

<br></br>

## **Objective**
By the end of this mini-project, you will be able to understand and apply statistical and ML methods for detecting anomalies.

In the Notebook, you will:
- explore the data set
- preprocess the data and conduct feature engineering
- apply statistical techniques to detect anomalies
- use ML algorithms to detect anomalies.

You will also write a report summarising the results of your findings and recommendations.

<br></br>

## **Assessment criteria**
By completing this project, you will be able to provide evidence that you can:
- demonstrate enhanced problem-solving skills and proposed strategic solutions by systematically analysing complex organisational challenges
- identify meaningful patterns in complex data to evidence advanced critical and statistical thinking skills
- select statistical techniques appropriate to a solutions design approach and evidence the ability to evaluate their effectiveness
- demonstrate enhanced data representation and improved model performance by systematically implementing relevant techniques
- design innovative solutions through critically selecting, evaluating and implementing effective unsupervised learning techniques.

<br></br>

## **Project guidance**
1. Import the required libraries and data set with the provided URL.
2. View the DataFrame and perform EDA, including identifying missing or duplicate values.
3. Generate the descriptive statistics of the data, including:
 - observing the mean for each feature
 - identifying the median
 - idenitfying the range values beyond the 95th percentile for at least two features.
4. Visualise the data to determine the distribution and extreme values.
5. Perform anomaly detection with a statistical method and identify possible anomalies. Specifically:
  - Use the interquartile range (IQR) method to identify outliers for each feature.
  - Create a new column (corresponding to each feature) that will indicate (in binary – 0,1) if the value of that feature is an outlier as per IQR calculations.
  - Use IQR to identify a sample as an outlier only if two or more of the features fall under an outlier category for a particular sample.
  - Record your thoughts and oberservations.
6. Perform anomaly detection with ML models:
  - Perform feature scaling to prepare the data for ML algorithms.
  - Using one-class SVM,
    - identify possible anomalies
    - visualise the output in 2D after performing PCA and ensure the outliers are in a different colour
    - apply different combinations of parameter settings to improve the model's outlier predictions to the expected 1-5%
    - record your insights about the use of this method.
  - Using Isolation Forest,
    - identify possible anomalies
    - visualise the output in 2D after performing PCA and ensure the outliers are in a different colour
    - apply different combinations of parameter settings to improve the model's outlier predictions to the expected 1-5%
    - record your insights about the use of this method.
7. Document your approach and major inferences from the data analysis and describe which method (and parameters) provided the best results and why.
8. When you’ve completed the activity:
  - Download your completed Notebook as an IPYNB (Jupyter Notebook) or PY (Python) file. Save the file as follows: LastName_FirstName_CAM_C101_W5_Mini-project.
  - Prepare a detailed report (between 800-1000 words) that includes:
    - an overview of your approach
    - a description of your analysis
    - an explanation of the insights you identified
    - a summary of which method gave the best results
    - a clear visualisation of your anomaly detection approach
    - an evaluation of the effectiveness of 2D visualisations in highlighting outliers
  - Save the document as a PDF named according to the following convention: LastName_FirstName_CAM_C101_W5_Mini-project.pdf.
  - You can submit your files individually or as a ZIP file. If you upload a ZIP file, use the correct naming convention: LastName_FirstName_CAM_C101_W5_Mini-project.zip.


<br></br>
> **Declaration**
>
> By submitting your project, you indicate that the work is your own and has been created with academic integrity. Refer to the Cambridge plagiarism regulations.

# Initial data evaluation
### 1. Import the required libraries and data set with the provided URL.
"""

# Import necessary libraries.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.svm import OneClassSVM
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
import random

# URL to import data set from GitHub.
url = 'https://raw.githubusercontent.com/fourthrevlxd/cam_dsb/main/engine.csv'

# Read the data from CSV file
df = pd.read_csv(url)

print(df.shape, "\n")

# Display DataFrame
df.head(19535)

"""### 2. View the DataFrame and perform EDA, including identifying missing or duplicate values."""

df.info()

# Check for missing values
print("\nMissing Values:")
print(df.isnull().sum())

# Check for duplicate rows
print("\nDuplicate Rows:")
print(df[df.duplicated()])

# Check data types of the columns
print("\nData Types:")
print(df.dtypes, "\n")

# Visualise Data
# df.hist(figsize=(8, 6))
# plt.tight_layout()
# plt.show()

"""# 3. Generate the descriptive statistics of the data, including:
- observing the mean for each feature
- identifying the median
- identifying the range values beyond the 95th percentile for at least two features.
"""

# Print Summary Statistics
print(df.describe(), '\n')

# print("95th Percentile:",'\n', df.quantile(0.95), '\n')

# 95th Percentile of Engine RPM
print("95th Percentile Engine rpm:", df['Engine rpm'].describe(percentiles=[.95]))
print("95th Percentile Engine rpm:", df['Engine rpm'].quantile(0.95), "\n")

# 95th Percentile of Coolant Pressure
print("95th Percentile Coolant pressure:", df['Coolant pressure'].describe(percentiles=[.95]))
print("95th Percentile Coolant pressure:", df['Coolant pressure'].quantile(0.95), "\n")

"""# 4. Visualise the data to determine the distribution and extreme values"""

# Drop rows with missing values for visualization purposes
df_clean = df.dropna()

# Generate histograms with different colors
def plot_histograms_with_colors(data):
    plt.figure(figsize=(12, 8))
    num_columns = len(data.columns)
    max_subplots_per_row = 3
    num_rows = -(-num_columns // max_subplots_per_row)

    fig, axes = plt.subplots(nrows=num_rows, ncols=max_subplots_per_row, figsize=(15, 5 * num_rows))
    colors = ['red', 'skyblue', 'green', 'violet', 'orange', 'cyan', 'purple', 'yellow']  # Define some colors

   # Flatten axes to iterate through them easily
    axes = axes.flatten()

    for i, column in enumerate(data.columns):
        color = random.choice(colors)  # Randomly assign a color
        ax = axes[i] # if num_columns > 1 else axes  # Handle single subplot case
        #ax.hist(data[column], bins=10, color=color, alpha=0.7)
        sns.histplot(data[column], bins=10, kde=True, color=color, ax=ax)
        ax.set_title(f'Histogram of {column}')  # Add title
        ax.set_xlabel(column)  # Label x-axis
        ax.set_ylabel('Frequency')  # Label y-axis
        ax.grid(axis='y', alpha=0.75)  # Add grid

    plt.tight_layout()  # Adjust spacing between subplots
    plt.show()  # Display the histograms

# Call the function
plot_histograms_with_colors(df_clean)

# Set up the plotting area
plt.figure(figsize=(12, 8))

# 1. Histogram to show the distribution of each numerical column
plt.subplot(2, 3, 1)
df_clean['Engine rpm'].hist(bins=10, color='skyblue', edgecolor='black', alpha=0.7)
plt.title('Histogram of Engine rpm')
plt.xlabel('Engine rpm')
plt.ylabel('Frequency')

plt.subplot(2, 3, 2)
df_clean['Lub oil pressure'].hist(bins=10, color='salmon', edgecolor='black', alpha=0.7)
plt.title('Histogram of Lub oil pressure')
plt.xlabel('Lub oil pressure')
plt.ylabel('Frequency')

plt.subplot(2, 3, 3)
df_clean['Fuel pressure'].hist(bins=10, color='yellow', edgecolor='black', alpha=0.7)
plt.title('Histogram of Fuel pressure')
plt.xlabel('Fuel pressure')
plt.ylabel('Frequency')

plt.subplot(2, 3, 4)
df_clean['Coolant pressure'].hist(bins=10, color='red', edgecolor='black', alpha=0.7)
plt.title('Histogram of Coolant pressure')
plt.xlabel('Coolant pressure')
plt.ylabel('Frequency')

plt.subplot(2, 3, 5)
df_clean['lub oil temp'].hist(bins=10, color='purple', edgecolor='black', alpha=0.7)
plt.title('Histogram of lub oil temp')
plt.xlabel('lub oil temp')
plt.ylabel('Frequency')

plt.subplot(2, 3, 6)
df_clean['Coolant temp'].hist(bins=10, color='violet', edgecolor='black', alpha=0.7)
plt.title('Histogram of Coolant temp')
plt.xlabel('Coolant temp')
plt.ylabel('Frequency')

# Display all the plots
plt.tight_layout()
plt.show()

# 2. Box plot to show the distribution and extreme values (outliers)
plt.figure(figsize=(12, 8))

plt.subplot(2, 3, 1)
sns.boxplot(x=df_clean['Engine rpm'], color='skyblue')
plt.title('Boxplot of Engine rpm\n')

plt.subplot(2, 3, 2)
sns.boxplot(x=df_clean['Lub oil pressure'], color='salmon')
plt.title('Boxplot of Lub oil pressure\n')

plt.subplot(2, 3, 3)
sns.boxplot(x=df_clean['Fuel pressure'], color='yellow')
plt.title('Boxplot of Fuel pressure')

plt.subplot(2, 3, 4)
sns.boxplot(x=df_clean['Coolant pressure'], color='red')
plt.title('Boxplot of Coolant pressure')

plt.subplot(2, 3, 5)
sns.boxplot(x=df_clean['lub oil temp'], color='purple')
plt.title('Boxplot of lub oil temp')

plt.subplot(2, 3, 6)
sns.boxplot(x=df_clean['Coolant temp'], color='violet')
plt.title('Boxplot of Coolant temp')

# Display all the plots
plt.tight_layout()
plt.show()

"""### 5. Use the interquartile range (IQR) method to identify outliers for each feature."""

# Create a new dataframe to hold binary outlier indicators
outlier_df = pd.DataFrame()

# Function to identify outliers using IQR method
def identify_outliers(df_column):
    Q1 = df_column.quantile(0.25)
    Q3 = df_column.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df_column[(df_column < lower_bound) | (df_column > upper_bound)]

    return outliers, lower_bound, upper_bound

for column in df.columns:
    outliers, lower_bound, upper_bound = identify_outliers(df[column])

    # Create a binary column for each feature (1 if outlier, 0 if not)
    outlier_df[column + '_outlier'] = df_clean[column].apply(lambda x: 1 if x in outliers.values else 0)

# Detect samples as outliers if two or more features have outliers
# Sum of 1's for each row, mark if 2 or more features are outliers
outlier_df['Outlier'] =( outlier_df.sum(axis=1) >=1 ).astype(int)

# Flag samples where at least 2 features are outliers
outlier_df['Outlier > 1'] = (outlier_df['Outlier'] >= 2).astype(int)

# Display the resulting dataframe with outlier information
print(outlier_df)

# Merge the binary outlier columns with the original dataframe
df_with_outliers = pd.concat([df_clean, outlier_df], axis=1)

# Display the resulting dataframe with outlier information
print(df_with_outliers)

# Identify observations where two or more features are flagged as outliers
outliers_with_multiple_flags = outlier_df[outlier_df['Outlier > 1'] == 2]

print("\nObservations with at least two features flagged as outliers:")
print(outliers_with_multiple_flags)

"""# Reflect

Write a brief paragraph highlighting your process and the rationale to showcase critical thinking and problem-solving.

> Select the pen from the toolbar to add your entry.

### Reference:
Devabrat, M., 2022. Predictive Maintenance on Ship's Main Engine using AI. Available at: https://dx.doi.org/10.21227/g3za-v415. [Accessed 5 March 2024]
"""